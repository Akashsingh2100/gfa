{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "as_input (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 25088)        14714688    as_input[0][0]                   \n",
      "                                                                 lpc_input_1[0][0]                \n",
      "                                                                 lpc_input_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "as_fc1 (Dense)                  (None, 1024)         25691136    model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lpc_input_1 (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lpc_input_2 (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           as_fc1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "as_fc2 (Dense)                  (None, 1024)         1049600     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lpc_fc1 (Dense)                 (None, 1024)         25691136    model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lpc_fc2 (Dense)                 (None, 1024)         25691136    model[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "as_output (Dense)               (None, 2)            2050        as_fc2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lpc (Lambda)                    (None, 1024)         0           lpc_fc1[0][0]                    \n",
      "                                                                 lpc_fc2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 92,839,746\n",
      "Trainable params: 78,125,058\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import math\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# Print available physical devices\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "def get_model():\n",
    "    # Load VGG16 with pre-trained weights and without the top layer\n",
    "    vgg16 = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    # Extract the output from the last layer of VGG16\n",
    "    last_output = vgg16.output\n",
    "    x = keras.layers.Flatten()(last_output)\n",
    "    share_weight_net = keras.Model(inputs=vgg16.input, outputs=x)\n",
    "    print(share_weight_net.summary())\n",
    "\n",
    "    # Define inputs\n",
    "    as_input = keras.Input(shape=(224, 224, 3), name=\"as_input\")\n",
    "    lpc_input_1 = keras.Input(shape=(224, 224, 3), name=\"lpc_input_1\")\n",
    "    lpc_input_2 = keras.Input(shape=(224, 224, 3), name=\"lpc_input_2\")\n",
    "    \n",
    "    # Anti-spoofing branch\n",
    "    as_flatten_1 = share_weight_net(as_input)\n",
    "    as_fc1 = keras.layers.Dense(1024, activation=\"relu\",kernel_regularizer=l2(0.001), name=\"as_fc1\")(as_flatten_1)\n",
    "    as_fc1 = Dropout(0.5)(as_fc1)\n",
    "    as_fc2 = keras.layers.Dense(1024, activation=\"relu\",kernel_regularizer=l2(0.001), name=\"as_fc2\")(as_fc1)\n",
    "    as_output = keras.layers.Dense(2, activation='sigmoid', name=\"as_output\")(as_fc2)\n",
    "\n",
    "    # Uncomment and complete if needed\n",
    "    #Local patch comparison branch\n",
    "    lpc_flatten_1 = share_weight_net(lpc_input_1)\n",
    "    lpc_fc_o1 = keras.layers.Dense(1024, activation=\"relu\", name=\"lpc_fc1\")(lpc_flatten_1)\n",
    "\n",
    "    lpc_flatten_2 = share_weight_net(lpc_input_2)\n",
    "    lpc_fc_o2 = keras.layers.Dense(1024, activation=\"relu\", name=\"lpc_fc2\")(lpc_flatten_2)\n",
    "\n",
    "    lpc = keras.layers.Lambda(lambda x: tf.math.square(x[0] - x[1]), name='lpc')([lpc_fc_o1, lpc_fc_o2])\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(\n",
    "        inputs=[as_input,lpc_input_1,lpc_input_2], \n",
    "        outputs=[as_output,lpc] \n",
    "    )\n",
    "\n",
    "    # Compile the model with appropriate losses and metrics\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            \"as_output\": keras.losses.SparseCategoricalCrossentropy(),\n",
    "            \"lpc\": tpc_loss},\n",
    "        loss_weights={\n",
    "            \"as_output\": 1.0,\n",
    "            \"lpc\": 2.5*math.exp(-5)\n",
    "        },\n",
    "        metrics={\"as_output\": 'accuracy'}\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def tpc_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(y_pred, axis=1, keepdims=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = get_model()\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index for attack samples...\n",
      "Loading index for real samples...\n",
      "[total:4292,real:1568,attack:2724]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, name, batch_size, attack_dir, real_dir):  # Fixed __init__\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.attack_dir = attack_dir\n",
    "        self.real_dir = real_dir\n",
    "        self.dataset = MsuMsfdDataset(batch_size, attack_dir, real_dir)\n",
    "\n",
    "        file_path, label_truth = self.dataset.load_idx()\n",
    "\n",
    "        # Encode the labels\n",
    "        self.encoding_truth = preprocessing.LabelEncoder()\n",
    "        self.encoding_truth.fit(label_truth)\n",
    "        self.list_label_truth = self.encoding_truth.transform(label_truth)\n",
    "\n",
    "        self.list_file_path_truth = file_path.copy()\n",
    "\n",
    "        self.shuffle_dataset()\n",
    "        self.len_dataset = len(self.list_file_path_truth)\n",
    "    \n",
    "\n",
    "        with open(\"config.yaml\", \"r\") as ymlfile:\n",
    "            cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "        self.standard_img_size = cfg['net']['input_img_size']\n",
    "\n",
    "        # Build dataset using tf.data for better performance\n",
    "        self.train_dataset = self.build_tf_dataset()\n",
    "\n",
    "    def shuffle_dataset(self):\n",
    "        self.list_file_path_truth, self.list_label_truth = shuffle(self.list_file_path_truth, self.list_label_truth,\n",
    "                                                                   random_state=10)\n",
    "\n",
    "    def load_and_preprocess_image(self, file_path, label):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_png(img, channels=3)\n",
    "        img = tf.image.resize(img, (self.standard_img_size, self.standard_img_size))\n",
    "        img = img / 255.0  # Normalize to [0, 1]\n",
    "        return img, label\n",
    "\n",
    "    def augment_image(self, img, label):\n",
    "        # Apply random flipping, brightness changes, etc.\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        return img, label\n",
    "\n",
    "    def build_tf_dataset(self):\n",
    "        # Create dataset from file paths and labels\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.list_file_path_truth, self.list_label_truth))\n",
    "        dataset = dataset.shuffle(buffer_size=self.len_dataset)  # Shuffle dataset\n",
    "        dataset = dataset.map(self.load_and_preprocess_image, num_parallel_calls=2)  # Load images\n",
    "        dataset = dataset.map(self.augment_image, num_parallel_calls=2)  # Data augmentation\n",
    "        dataset = dataset.batch(self.batch_size)  # Batch the data\n",
    "        dataset = dataset.prefetch(buffer_size=2)  # Prefetch for optimal performance\n",
    "        return dataset\n",
    "\n",
    "    def generate_minibatch(self):\n",
    "        start_idx = 0\n",
    "        total_batches = (self.len_dataset + self.batch_size - 1) // self.batch_size\n",
    "        print(\"Using tf.data pipeline for minibatch generation\")\n",
    "\n",
    "        with tqdm(total=total_batches, desc=\"Generating Minibatches\", unit=\"batch\") as pbar:\n",
    "            for batch in self.train_dataset:\n",
    "                batch_img_4_truth, batch_label_truth = batch\n",
    "\n",
    "                # Select random images for LPC loss\n",
    "                batch_random_1 = []\n",
    "                batch_random_2 = []\n",
    "                list_random_images_path1 = random.sample(self.list_file_path_truth, k=len(batch_img_4_truth))\n",
    "                list_random_images_path2 = random.sample(self.list_file_path_truth, k=len(batch_img_4_truth))\n",
    "\n",
    "                for file_path_1 in list_random_images_path1:\n",
    "                    img1 = self.load_and_preprocess_image(file_path_1, None)[0]\n",
    "                    batch_random_1.append(img1)\n",
    "\n",
    "                for file_path_2 in list_random_images_path2:\n",
    "                    img2 = self.load_and_preprocess_image(file_path_2, None)[0]\n",
    "                    batch_random_2.append(img2)\n",
    "\n",
    "                batch_img_random_1 = tf.stack(batch_random_1)\n",
    "                batch_img_random_2 = tf.stack(batch_random_2)\n",
    "                batch_label_random = tf.zeros(len(batch_img_random_1), dtype=tf.float32)\n",
    "\n",
    "                start_idx += self.batch_size\n",
    "                pbar.update(1)\n",
    "                yield batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random\n",
    "\n",
    "\n",
    "class MsuMsfdDataset:\n",
    "    def __init__(self, batch_size, attack_dir, real_dir):  # Fixed __init__\n",
    "        self.batch_size = batch_size\n",
    "        self.attack_dir = attack_dir\n",
    "        self.real_dir = real_dir\n",
    "\n",
    "    def load_idx(self):\n",
    "        list_file_path = []\n",
    "        list_label_truth = []\n",
    "        attack_dir = self.attack_dir\n",
    "        real_dir = self.real_dir\n",
    "        i = 0\n",
    "        j= 0\n",
    "        print('Loading index for attack samples...')\n",
    "        for pic in os.listdir(attack_dir):\n",
    "            list_file_path.append(os.path.join(attack_dir, pic))\n",
    "            list_label_truth.append('attack')\n",
    "            i=i+1\n",
    "\n",
    "        print('Loading index for real samples...')\n",
    "        for pic in os.listdir(real_dir):\n",
    "            list_file_path.append(os.path.join(real_dir, pic))\n",
    "            list_label_truth.append('real')\n",
    "            j = j+1\n",
    "        \n",
    "        print(f\"[total:{i+j},real:{j},attack:{i}]\")\n",
    "        return list_file_path, list_label_truth\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    msumsfd_dataset = Dataset('replayattack', 32,attack_dir= r\"E:\\akash singh\\GFA-CNN-new\\GFA-CNN-master\\GFA-CNN-master\\dataset_small1\\msumsfd_gfacnn\\attack\",\n",
    "                              real_dir=r\"E:\\akash singh\\GFA-CNN-new\\GFA-CNN-master\\GFA-CNN-master\\dataset_small1\\msumsfd_gfacnn\\real\")\n",
    "#     sum = 0\n",
    "#     for img_4_truth, label_truth, img_random_1, img_random_2, label_random in msumsfd_dataset.generate_minibatch():\n",
    "#         print(label_truth)\n",
    "#         tensor_sum = tf.reduce_sum(label_truth)\n",
    "#         sum = sum+tensor_sum.numpy()\n",
    "\n",
    "# # Print the result\n",
    "# print(\"Sum of tensor elements:\", sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Physical devices cannot be modified after being initialized\n",
      "Loading index for attack samples...\n",
      "Loading index for real samples...\n",
      "[total:4292,real:1568,attack:2724]\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Preprocessing data ...\n",
      "Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch number: 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tf.data pipeline for minibatch generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 33s 2s/sample - loss: 33.2304 - as_output_loss: 5.8125 - lpc_loss: 1472.3317 - as_output_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 18s 1s/sample - loss: 3.8197 - as_output_loss: 1.9232 - lpc_loss: 0.5396 - as_output_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 1s 64ms/sample - loss: 6.4563 - as_output_loss: 4.9256 - lpc_loss: 0.0615 - as_output_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 11s 683ms/sample - loss: 3.8115 - as_output_loss: 2.4171 - lpc_loss: 0.1994 - as_output_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 14s 879ms/sample - loss: 1.8993 - as_output_loss: 0.5526 - lpc_loss: 0.0181 - as_output_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "16/16 [==============================] - 1s 71ms/sample - loss: 3.1594 - as_output_loss: 1.8185 - lpc_loss: 1.0275 - as_output_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Minibatches:   2%|▏         | 6/269 [01:51<1:21:09, 18.52s/batch]\n",
      "Batches:   2%|▏         | 6/268 [01:51<1:20:51, 18.52s/it]\n",
      "Epochs:   0%|          | 0/1 [01:51<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ReadFile\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         tld.op_callbacks, filename)\n\u001b[0m\u001b[0;32m    550\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c6a6e1b720b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random in tqdm(\n\u001b[1;32m---> 48\u001b[1;33m                  dataset.generate_minibatch(), desc='Batches', total=len(dataset.list_file_path_truth) // batch):\n\u001b[0m\u001b[0;32m     49\u001b[0m             GFA_CNN.fit(\n\u001b[0;32m     50\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[1;34m\"as_input\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_img_4_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lpc_input_1\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_img_random_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lpc_input_2\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_img_random_2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fb05192cf6aa>\u001b[0m in \u001b[0;36mgenerate_minibatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfile_path_1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_random_images_path1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                     \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m                     \u001b[0mbatch_random_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fb05192cf6aa>\u001b[0m in \u001b[0;36mload_and_preprocess_image\u001b[1;34m(self, file_path, label)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_and_preprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandard_img_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandard_img_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    552\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         return read_file_eager_fallback(\n\u001b[1;32m--> 554\u001b[1;33m             filename, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    555\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[1;34m(filename, name, ctx)\u001b[0m\n\u001b[0;32m    590\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[1;32m--> 592\u001b[1;33m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m    593\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import model\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure GPU memory growth (if needed)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open(\"config.yaml\", \"r\") as ymlfile:\n",
    "        cfg = yaml.safe_load(ymlfile)  # Use safe_load for security\n",
    "\n",
    "    epoch = cfg['training']['epoch']\n",
    "    batch = cfg['training']['batch']\n",
    "\n",
    "    attack_dir = r\"dataset_small1\\msumsfd_gfacnn\\attack\"\n",
    "    real_dir = r\"dataset_small1\\msumsfd_gfacnn\\real\"\n",
    "    dataset = Dataset('MSU-MSFD', batch_size=batch, attack_dir=attack_dir, real_dir=real_dir)\n",
    "    GFA_CNN = model.get_model()\n",
    "\n",
    "    checkpoint_filepath = cfg['training']['checkpoint']\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    print('Preprocessing data ...')\n",
    "\n",
    "    print('Training ...')\n",
    "    j = 1\n",
    "    for e in tqdm(range(epoch), desc='Epochs'):\n",
    "        print(f\"[epoch number: {j}]\")\n",
    "        dataset.shuffle_dataset()\n",
    "        i = 1\n",
    "        for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random in tqdm(\n",
    "                 dataset.generate_minibatch(), desc='Batches', total=len(dataset.list_file_path_truth) // batch):\n",
    "            GFA_CNN.fit(\n",
    "                {\"as_input\": batch_img_4_truth, \"lpc_input_1\": batch_img_random_1, \"lpc_input_2\": batch_img_random_2},\n",
    "                {\"as_output\": batch_label_truth, 'lpc': batch_label_random},\n",
    "                epochs=1,\n",
    "                batch_size=4,\n",
    "                callbacks=[model_checkpoint_callback],\n",
    "                verbose=1\n",
    "            )\n",
    "            print(f\"counting iterations {i}\")\n",
    "            i += 1\n",
    "        j += 1\n",
    "\n",
    "    print(\"Saving the model...\")\n",
    "    GFA_CNN.save('gfamodel.keras') \n",
    "    print(\"model saved\")\n",
    "\n",
    "    # Load the testing dataset\n",
    "    attack_dir_test = r\"dataset_small1\\msumsfd_gfacnn_test1\\attack\"\n",
    "    real_dir_test = r\"dataset_small1\\msumsfd_gfacnn_test1\\real\"\n",
    "    test_dataset = Dataset('MSU-MSFD', batch_size=batch, attack_dir=attack_dir_test, real_dir=real_dir_test)\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2 in test_dataset.generate_minibatch():\n",
    "        predictions = GFA_CNN.predict({\n",
    "            \"as_input\": batch_img_4_truth,\n",
    "            \"lpc_input_1\": batch_img_random_1,\n",
    "            \"lpc_input_2\": batch_img_random_2\n",
    "        })\n",
    "\n",
    "        y_true.extend(batch_label_truth)\n",
    "        y_pred.extend(predictions[0])  # Adjust according to your output names\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = y_pred[:, 1]  # Assuming first column represents positive class probability\n",
    "\n",
    "    def calculate_eer(y_true, y_pred):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        fnr = 1 - tpr\n",
    "        eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "        eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "        return eer\n",
    "\n",
    "    def calculate_hter(eer, y_true, y_pred):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        fnr = 1 - tpr\n",
    "        threshold = np.interp(eer, fpr, tpr)\n",
    "        hter = (fpr[np.argmin(np.abs(threshold - tpr))] + fnr[np.argmin(np.abs(threshold - fnr))]) / 2\n",
    "        return hter\n",
    "\n",
    "    eer = calculate_eer(y_true, y_pred)\n",
    "    print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "\n",
    "    hter = calculate_hter(eer, y_true, y_pred)\n",
    "    print(f\"Half Total Error Rate (HTER): {hter:.4f}\")\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "from datasets import Dataset\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from model import tpc_loss\n",
    "\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as ymlfile:\n",
    "        cfg = yaml.safe_load(ymlfile)  # Use safe_load for security\n",
    "\n",
    "# Define the custom loss function again\n",
    "def tpc_loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(y_pred, axis=1, keepdims=True)\n",
    "\n",
    "# Load the model and specify custom loss function\n",
    "GFA_CNN = tf.keras.models.load_model(\"gfamodel.keras\",custom_objects={'tpc_loss': tpc_loss})\n",
    "print(f\"Model loaded\")\n",
    "\n",
    " # Load the testing dataset\n",
    "attack_dir_test = r\"dataset_small1\\msumsfd_gfacnn_test\\attack\"\n",
    "real_dir_test = r\"dataset_small1\\msumsfd_gfacnn_test\\real\"\n",
    "test_dataset = Dataset('replayattack_test', batch_size=16, attack_dir=attack_dir_test, real_dir=real_dir_test)  # Adjust as necessary\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random in test_dataset.generate_minibatch():\n",
    "    # Make predictions\n",
    "    predictions = GFA_CNN.predict({\n",
    "        \"as_input\": batch_img_4_truth,\n",
    "        \"lpc_input_1\": batch_img_random_1,\n",
    "        \"lpc_input_2\": batch_img_random_2,\n",
    "    })\n",
    "\n",
    "    # Collect true labels and predictions\n",
    "    y_true.extend(batch_label_truth)\n",
    "    y_pred.extend(predictions[0])  # Adjust according to your output names\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = y_pred[:, 1]  # Assuming second column represents positive class probability\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Calculate EER and HTER\n",
    "def calculate_eer(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    return eer\n",
    "\n",
    "def calculate_hter(eer, y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    threshold = np.interp(eer, fpr, tpr)\n",
    "    hter = (fpr[np.argmin(np.abs(threshold - tpr))] + fnr[np.argmin(np.abs(threshold - fnr))]) / 2\n",
    "    return hter\n",
    "\n",
    "# Calculate EER\n",
    "eer = calculate_eer(y_true, y_pred)\n",
    "print(f\"Equal Error Rate (EER): {eer*100:.4f}\")\n",
    "\n",
    "# Calculate HTER\n",
    "hter = calculate_hter(eer, y_true, y_pred)\n",
    "print(f\"Half Total Error Rate (HTER): {hter*100:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def plot_metrics(y_true, y_pred):\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')  # Use 'binary' for binary classification\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "    # Store the metrics in a dictionary for easy plotting\n",
    "    metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "    print(metrics)\n",
    "    \n",
    "    # Plot the metrics\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(metrics.keys(), metrics.values(), color=['blue', 'green', 'red', 'purple'])\n",
    "\n",
    "    # Set plot labels and title\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim([0, 1])  # The metrics are in the range [0, 1]\n",
    "    ax.set_title('Classification Metrics')\n",
    "\n",
    "    # Display the values on top of each bar\n",
    "    for i, v in enumerate(metrics.values()):\n",
    "        ax.text(i, v + 0.01, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "y_pred1 = (y_pred>0.5).astype(int)\n",
    "plot_metrics(y_true,y_pred1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
