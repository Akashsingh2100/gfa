{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4472333447773358521\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3055235892\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3036941897596800421\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18107 images belonging to 2 classes.\n",
      "Found 24073 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 566 steps\n",
      "Epoch 1/5\n",
      "284/566 [==============>...............] - ETA: 6:29 - loss: 0.1909 - accuracy: 0.9563"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  OSError: image file is truncated (32 bytes not processed)\nTraceback (most recent call last):\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\Image.py\", line 1989, in resize\n    self.load()\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\ImageFile.py\", line 250, in load\n    \"image file is truncated \"\n\nOSError: image file is truncated (32 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[Shape_15/_8]]\n  (1) Unknown:  OSError: image file is truncated (32 bytes not processed)\nTraceback (most recent call last):\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\Image.py\", line 1989, in resize\n    self.load()\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\ImageFile.py\", line 250, in load\n    \"image file is truncated \"\n\nOSError: image file is truncated (32 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_3771]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-01956e38cd4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m#validation_data=val_generator,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  OSError: image file is truncated (32 bytes not processed)\nTraceback (most recent call last):\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\Image.py\", line 1989, in resize\n    self.load()\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\ImageFile.py\", line 250, in load\n    \"image file is truncated \"\n\nOSError: image file is truncated (32 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[Shape_15/_8]]\n  (1) Unknown:  OSError: image file is truncated (32 bytes not processed)\nTraceback (most recent call last):\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\", line 975, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\Image.py\", line 1989, in resize\n    self.load()\n\n  File \"c:\\Users\\akash\\anaconda3\\envs\\env_gpu\\lib\\site-packages\\PIL\\ImageFile.py\", line 250, in load\n    \"image file is truncated \"\n\nOSError: image file is truncated (32 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_3771]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Set the paths to your dataset directory\n",
    "train_dir = r\"E:\\akash singh\\GFA-CNN-new\\GFA-CNN-master\\GFA-CNN-master\\dataset_new\\msumsfd_gfacnn\"\n",
    "validation_dir = r\"E:\\akash singh\\GFA-CNN-new\\GFA-CNN-master\\GFA-CNN-master\\dataset_new\\msumsfd_gfacnn_test\"\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # Keep the target size consistent\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),  # Keep the target size consistent with training data\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load the pre-trained VGG16 model + higher-level layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024\n",
    "    , activation='relu')(x)  # Custom dense layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    #validation_data=val_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-45cec787d609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Get predictions from the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Convert predictions to binary values (0 or 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Directory of test data\n",
    "test_dir = r\"E:\\dataset_new_norway\\archive\\Railway Track fault Detection Updated\\Test\"\n",
    "\n",
    "# Data generator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important to set shuffle=False for accurate evaluation\n",
    ")\n",
    "\n",
    "# Get predictions from the model\n",
    "predictions = model.predict(test_data, verbose=1)\n",
    "\n",
    "# Convert predictions to binary values (0 or 1)\n",
    "predicted_classes = (predictions > 0.5).astype('int32')\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.8854303e-07]\n",
      " [8.5766811e-04]\n",
      " [7.1180339e-06]\n",
      " [5.7128291e-05]\n",
      " [5.8110007e-05]\n",
      " [2.9754097e-05]\n",
      " [2.3955128e-05]\n",
      " [4.5730700e-04]\n",
      " [9.9917108e-01]\n",
      " [1.7740569e-03]\n",
      " [2.0079412e-03]\n",
      " [7.9000674e-06]\n",
      " [2.8379713e-05]\n",
      " [2.8711295e-06]\n",
      " [1.5156312e-05]\n",
      " [6.0400888e-03]\n",
      " [1.1862468e-05]\n",
      " [4.9706858e-05]\n",
      " [9.7740540e-06]\n",
      " [4.6665609e-06]\n",
      " [1.6151762e-05]\n",
      " [3.4350657e-04]\n",
      " [1.4655186e-06]\n",
      " [1.7940856e-06]\n",
      " [6.3714547e-06]\n",
      " [2.8999366e-02]\n",
      " [7.7694684e-04]\n",
      " [5.5228807e-06]\n",
      " [5.4638600e-05]\n",
      " [3.6602105e-05]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy: 73.15%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert probabilities to binary class labels (0 or 1)\n",
    "predicted_classes = (history1 > 0.5).astype(int)\n",
    "\n",
    "# Extract the true labels from the test data\n",
    "y_true = test_data.classes\n",
    "print(history1[0:30])\n",
    "print(y_true[0:30])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Loading model weights from ./checkpoints1/chkpt...\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints1/chkpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23708/905468839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading model weights from {checkpoint_filepath}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mGFA_CNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model loaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/gfacnn1/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/gfacnn1/lib/python3.7/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoints1/chkpt"
     ]
    }
   ],
   "source": [
    "import model\n",
    "from datasets import Dataset\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use this if you want to specify GPU\n",
    "\n",
    "def calculate_eer(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    return eer\n",
    "\n",
    "def calculate_hter(eer, y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    threshold = np.interp(eer, fpr, tpr)\n",
    "    hter = (fpr[np.argmin(np.abs(threshold - tpr))] + fnr[np.argmin(np.abs(threshold - fnr))]) / 2\n",
    "    return hter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the configuration file\n",
    "    with open(\"H:\\akash singh\\GFA-CNN-new\\GFA-CNN-master\\GFA-CNN-master\\config.yaml\", \"r\") as ymlfile:\n",
    "        cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "    # Load the model\n",
    "    GFA_CNN = model.get_model()\n",
    "    checkpoint_filepath = cfg['training']['checkpoint']\n",
    "\n",
    "    print(f\"Loading model weights from {checkpoint_filepath}...\")\n",
    "    GFA_CNN.load_weights(checkpoint_filepath)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Load the testing dataset\n",
    "    batch = cfg['training']['batch']\n",
    "    attack_dir_test = r\"/home/ml/dataset1/msumsfd_gfacnn_test/attack\"\n",
    "    real_dir_test = r\"/home/ml/dataset1/msumsfd_gfacnn_test/real\"\n",
    "    test_dataset = Dataset('replayattack_test', batch_size=batch, attack_dir=attack_dir_test, real_dir=real_dir_test)\n",
    "\n",
    "    # Collect predictions and true labels\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    print(\"Generating predictions on the test dataset...\")\n",
    "    for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random in tqdm(test_dataset.generate_minibatch(), desc='Testing'):\n",
    "        predictions = GFA_CNN.predict({\n",
    "            \"as_input\": batch_img_4_truth,\n",
    "            \"lpc_input_1\": batch_img_random_1,\n",
    "            \"lpc_input_2\": batch_img_random_2,\n",
    "        })\n",
    "        y_true.extend(batch_label_truth)\n",
    "        y_pred.extend(predictions[0])  # Adjust according to your output names\n",
    "\n",
    "    # Convert lists to numpy arrays for evaluation\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = y_pred[:, 0]  # Assuming first column represents positive class probability\n",
    "\n",
    "    print(f\"y_true shape: {y_true.shape}\")\n",
    "    print(f\"y_pred shape: {y_pred.shape}\")\n",
    "\n",
    "    # Calculate EER and HTER\n",
    "    eer = calculate_eer(y_true, y_pred)\n",
    "    print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "\n",
    "    hter = calculate_hter(eer, y_true, y_pred)\n",
    "    print(f\"Half Total Error Rate (HTER): {hter:.4f}\")\n",
    "\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading index for attack\n",
      "loading index for real\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, name, batch_size, attack_dir, real_dir):\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        self.attack_dir = attack_dir\n",
    "        self.real_dir = real_dir\n",
    "        self.dataset = MsuMsfdDataset(batch_size, attack_dir, real_dir)\n",
    "\n",
    "        file_path, label_truth = self.dataset.load_idx()\n",
    "        # encode the label\n",
    "        self.encoding_truth = preprocessing.LabelEncoder()\n",
    "        self.encoding_truth.fit(label_truth)\n",
    "        self.list_label_truth = self.encoding_truth.transform(label_truth)\n",
    "\n",
    "        self.list_file_path_truth = file_path.copy()\n",
    "\n",
    "        self.shuffle_dataset()\n",
    "        self.len_dataset = len(self.list_file_path_truth)\n",
    "\n",
    "        with open(\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/config.yaml\", \"r\") as ymlfile:\n",
    "            cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "        self.standard_img_size = cfg['net']['input_img_size']\n",
    "\n",
    "    def shuffle_dataset(self):\n",
    "        self.list_file_path_truth, self.list_label_truth = shuffle(self.list_file_path_truth, self.list_label_truth,\n",
    "                                                                   random_state=10)\n",
    "\n",
    "    def generate_minibatch(self):\n",
    "        start_idx = 0\n",
    "        total_batches = (self.len_dataset + self.batch_size - 1) // self.batch_size\n",
    "        print(\"using minibatch\")\n",
    "\n",
    "        with tqdm(total=total_batches, desc=\"Generating Minibatches\", unit=\"batch\") as pbar:\n",
    "            while True:\n",
    "                # crop sub lists from the long lists\n",
    "                if start_idx + self.batch_size <= self.len_dataset:\n",
    "                    batch_file_path_truth = self.list_file_path_truth[start_idx: start_idx + self.batch_size]\n",
    "                    batch_label_truth = self.list_label_truth[start_idx: start_idx + self.batch_size]\n",
    "                    print(f\"start_idx:{start_idx}, len_dataset: {self.len_dataset}, batch_size: {self.batch_size}\")\n",
    "                elif start_idx < self.len_dataset < (start_idx + self.batch_size):\n",
    "                    batch_file_path_truth = self.list_file_path_truth[start_idx: self.len_dataset]\n",
    "                    batch_label_truth = self.list_label_truth[start_idx: self.len_dataset]\n",
    "                elif start_idx >= self.len_dataset:\n",
    "                    break\n",
    "\n",
    "                # load image to numpy array\n",
    "                batch_img_4_truth = None\n",
    "                for file_path_truth in batch_file_path_truth:\n",
    "                    img = cv2.imread(file_path_truth)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (self.standard_img_size, self.standard_img_size))\n",
    "                    img = np.expand_dims(img, axis=0)\n",
    "                    img = img / 255.0  # Scale image to [0, 1]\n",
    "                    if batch_img_4_truth is None:\n",
    "                        batch_img_4_truth = img\n",
    "                    else:\n",
    "                        batch_img_4_truth = np.concatenate((batch_img_4_truth, img), axis=0)\n",
    "\n",
    "                # select random images for lpc loss\n",
    "                batch_random_1 = []\n",
    "                batch_random_2 = []\n",
    "                list_random_images_path1 = random.sample(self.list_file_path_truth, k=len(batch_img_4_truth))\n",
    "                list_random_images_path2 = random.sample(self.list_file_path_truth, k=len(batch_img_4_truth))\n",
    "                for file_path_1 in list_random_images_path1:\n",
    "                    img = cv2.imread(file_path_1)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (self.standard_img_size, self.standard_img_size))\n",
    "                    img = img / 255.0  # Scale image to [0, 1]\n",
    "                    batch_random_1.append(img)\n",
    "\n",
    "                for file_path_2 in list_random_images_path2:\n",
    "                    img2 = cv2.imread(file_path_2)\n",
    "                    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "                    img2 = cv2.resize(img2, (self.standard_img_size, self.standard_img_size))\n",
    "                    img2 = img2 / 255.0  # Scale image to [0, 1]\n",
    "                    batch_random_2.append(img2)\n",
    "\n",
    "                batch_img_random_1 = np.array(batch_random_1)\n",
    "                batch_img_random_2 = np.array(batch_random_2)\n",
    "                batch_label_random = [0 for i in range(len(batch_img_random_1))]\n",
    "                batch_label_random = np.asarray(batch_label_random).astype(float)\n",
    "\n",
    "                start_idx += self.batch_size\n",
    "                pbar.update(1)\n",
    "                yield batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random\n",
    "\n",
    "class MsuMsfdDataset:\n",
    "    def __init__(self, batch_size, attack_dir, real_dir):\n",
    "        self.batch_size = batch_size\n",
    "        self.attack_dir = attack_dir\n",
    "        self.real_dir = real_dir\n",
    "\n",
    "    def load_idx(self):\n",
    "        list_file_path = []\n",
    "        list_label_truth = []\n",
    "        attack_dir = self.attack_dir\n",
    "        real_dir = self.real_dir\n",
    "        \n",
    "        print('loading index for attack')\n",
    "        for client in os.listdir(attack_dir):\n",
    "            client_dir = os.path.join(attack_dir, client)\n",
    "            for pic in os.listdir(client_dir):\n",
    "                list_file_path.append(os.path.join(client_dir, pic))\n",
    "                list_label_truth.append('attack')\n",
    "        print('loading index for real')\n",
    "        for client in os.listdir(real_dir):\n",
    "            client_dir = os.path.join(real_dir, client)\n",
    "            for pic in os.listdir(client_dir):\n",
    "                list_file_path.append(os.path.join(client_dir, pic))\n",
    "                list_label_truth.append('real')\n",
    "        return list_file_path, list_label_truth\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    msumsfd_dataset = Dataset(\n",
    "        'replayattack',\n",
    "        32,\n",
    "        attack_dir=r\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/dataset1/msumsfd_gfacnn_test/attack\",\n",
    "        real_dir=r\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/dataset1/msumsfd_gfacnn_test/real\"\n",
    "    )\n",
    "\n",
    "    # img_4_truth, label_truth, img_random_1, img_random_2, label_random = msumsfd_dataset.generate_minibatch()\n",
    "\n",
    "    # Debugging: Save the images and plot them\n",
    "    # for i, img in enumerate(img_4_truth[:4]):  # Save only first 4 images for debugging\n",
    "    #     path = os.path.join('debug_as', f'img_{i}.jpg')\n",
    "    #     cv2.imwrite(path, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # h, w = 10, 10  # for raster image\n",
    "    # nrows, ncols = 2, 2  # array of sub-plots\n",
    "    # figsize = [6, 8]\n",
    "    # fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "    # plot simple raster image on each sub-plot\n",
    "    # for i, axi in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at r\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/saved_model\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10507/1970659008.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_save_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mGFA_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'tpc_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtpc_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model loaded from {model_save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/gfacnn1/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/gfacnn1/lib/python3.7/site-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         raise IOError(\n\u001b[0;32m--> 228\u001b[0;31m                             \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                         )\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at r\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/saved_model\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Add the directory containing 'datasets.py' to sys.path\n",
    "sys.path.append('/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/')\n",
    "\n",
    "from datasets import Dataset  # Now import the Dataset class\n",
    "from tensorflow.keras.models import load_model\n",
    "from model import tpc_loss  # Ensure this is correctly imported\n",
    "\n",
    "# Load configuration\n",
    "with open(\"/home/ml/akash singh/GFA-CNN-new/GFA-CNN-master/GFA-CNN-master/config.yaml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)  # Use safe_load for security\n",
    "\n",
    "# Load the saved model with the custom loss function\n",
    "print(\"Loading the model...\")\n",
    "model_save_path = cfg['training']['model_save_path']\n",
    "GFA_CNN = load_model(model_save_path, custom_objects={'tpc_loss': tpc_loss})\n",
    "print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "# Load the testing dataset\n",
    "batch_size = 32  # Adjust batch size according to your requirement\n",
    "attack_dir_test = r\"/home/ml/dataset1/msumsfd_gfacnn_test/attack\"\n",
    "real_dir_test = r\"/home/ml/dataset1/msumsfd_gfacnn_test/real\"\n",
    "test_dataset = Dataset('replayattack_test', batch_size=batch_size, attack_dir=attack_dir_test, real_dir=real_dir_test)  # Adjust as necessary\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch_img_4_truth, batch_label_truth, batch_img_random_1, batch_img_random_2, batch_label_random in test_dataset.generate_minibatch():\n",
    "    # Make predictions\n",
    "    predictions = GFA_CNN.predict({\n",
    "        \"as_input\": batch_img_4_truth,\n",
    "        \"lpc_input_1\": batch_img_random_1,\n",
    "        \"lpc_input_2\": batch_img_random_2,\n",
    "    })\n",
    "\n",
    "    # Collect true labels and predictions\n",
    "    print(f\"[predictions array: {predictions}]\")\n",
    "    print(f\"[y_pred: {predictions[0]}]\")\n",
    "    print(f\"[y_true: {batch_label_truth}]\")\n",
    "    sys.exit()\n",
    "    y_true.extend(batch_label_truth)\n",
    "    y_pred.extend(predictions[0])  # Adjust according to your output names\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = y_pred[:, 1]  # Assuming the second column represents positive class probability\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Calculate EER and HTER\n",
    "def calculate_eer(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    return eer\n",
    "\n",
    "def calculate_hter(eer, y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    fnr = 1 - tpr\n",
    "    threshold = np.interp(eer, fpr, tpr)\n",
    "    hter = (fpr[np.argmin(np.abs(threshold - tpr))] + fnr[np.argmin(np.abs(threshold - fnr))]) / 2\n",
    "    return hter\n",
    "\n",
    "# Calculate EER\n",
    "eer = calculate_eer(y_true, y_pred)\n",
    "print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "\n",
    "# Calculate HTER\n",
    "hter = calculate_hter(eer, y_true, y_pred)\n",
    "print(f\"Half Total Error Rate (HTER): {hter:.4f}\")\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'panda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpanda\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdetaset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'panda'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfacnn1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd6b959bbbf046ac107623f298e4a27ac7470c15cf68ef420e8f1f63279e93d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
